{
    "title": "RAG Web browser",
    "description": "Web browser for a retrieval augmented generation workflows. Retrieve and return website content from the top Google Search Results Pages",
    "type": "object",
    "schemaVersion": 1,
    "properties": {
        "query": {
            "title": "Search term(s)",
            "type": "string",
            "description": "Use regular search words or enter Google Search URLs. You can also apply [advanced Google search techniques](https://blog.apify.com/how-to-scrape-google-like-a-pro/), such as <code>AI site:twitter.com</code> or <code>javascript OR python</code>.",
            "prefill": "site:apify.com apify\nllm",
            "editor": "textarea",
            "pattern": "[^\\s]+"
        },
        "maxResults": {
            "title": "Max results to return",
            "type": "integer",
            "description": "",
            "prefill": 3.0,
            "minimum": 1.0
        },
        "outputFormats": {
            "title": "Output formats",
            "type": "array",
            "description": "Select the output formats you want to retrieve from the search results.",
            "editor": "select",
            "default": ["text"],
            "items": {
                "type": "string",
                "enum": ["text", "markdown", "html"],
                "enumTitles": ["Text", "Markdown", "HTML"]
            }
        },
        "proxyConfigurationSearch": {
            "title": "Search: Proxy configuration",
            "type": "string",
            "description": "Enables loading the search results using different proxies.",
            "editor": "select",
            "default": "GOOGLE_SERP",
            "enum": ["GOOGLE_SERP", "SHADER"]
        },
        "proxyConfiguration": {
            "title": "Crawler: Proxy configuration",
            "type": "object",
            "description": "Enables loading the websites from IP addresses in specific geographies and to circumvent blocking.",
            "default": {
                "useApifyProxy": true
            },
            "prefill": {
                "useApifyProxy": true
            },
            "editor": "proxy",
            "sectionCaption": "Crawler Settings"
        },
        "maxRequestRetries": {
            "title": "Maximum number of retries on network / server errors",
            "type": "integer",
            "description": "The maximum number of times the crawler will retry the request on network, proxy or server errors. If the (n+1)-th request still fails, the crawler will mark this request as failed.",
            "minimum": 0,
            "maximum": 3,
            "default": 1
        },
        "requestTimeoutSecs": {
            "title": "Request timeout",
            "type": "integer",
            "description": "Timeout (in seconds) for making the request and processing its response.",
            "minimum": 1,
            "maximum": 600,
            "default": 20
        }
    }
}
